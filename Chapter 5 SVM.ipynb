{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machine is an algorithm to classify data. The line that separates the data into two subsets will obtain the greatest __margin__.To maximize __margin__, a constrained optimization problem is used. If we strictly impose that all instances be off the _street_, this is called __hard margin classification__. There are two issues with __hard margin classification__: (1) it works if the data is linearly separable (2) it is quite sensitive to outliers. To avoid this issue, it is preferable to use a more flexible model. The objective is to find a good balance between keeping the street as large as possible and limitting the margin violations. This is called __soft margin classification__.\n",
    "\n",
    "In __ScikitLearn's SVM__ classes, you can control __margin violations__ using the $C$ hyperparameter: a value leads to a wider street but more margin violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scalar', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "rc('text', usetex = True)\n",
    "rc('font', family='serif')\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris ['data'][:, (2, 3)]\n",
    "y = (iris ['target'] == 2).astype(np.float64)\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('linear_svc', LinearSVC(C=1, loss='hinge')),\n",
    "])\n",
    "\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although linear SVM classifiers are efficient and work surprisingly well in many cases, many datasets are not even close to being separable. One approach is to add more features such as polynomial features. To implement this, you can create a __Pipeline__ containing a __PolynomialFeatures__ transformer, followed by a __StandardScaler__ and a __LinearSVC__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1da47f80ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
    "\n",
    "def plot_dataset(X, y, axes):\n",
    "    plt.plot(X[:, 0][y == 0], X[:, 1][y == 0], 'bs')\n",
    "    plt.plot(X[:, 0][y == 1], X[:, 1][y == 1], 'g^')\n",
    "    plt.axis(axes)\n",
    "    plt.grid(True, which='both')\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.ylabel(r'$x_2$')\n",
    "\n",
    "plot_dataset(X, y, [-1.5, 2.5, -1., 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('ply_features', PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=2000, multi_class='ovr',\n",
       "     penalty='l2', random_state=42, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_svm_clf = Pipeline(\n",
    "[\n",
    "    ('ply_features', PolynomialFeatures(degree=3)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', LinearSVC(C=10, max_iter = 2000, loss='hinge', random_state=42))\n",
    "]\n",
    ")\n",
    "\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, PolynomialFeatures cannot deal with very complex datasets and with high polynomial degree it creates a huge number of features, making the model too slow. Fortunately, when using __SVM__, you can apply an almost miraculous mathematical technique called __kernel trick__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', SVC(C=5, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "poly_kernel_svm_clf = Pipeline(\n",
    "[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='poly', degree=3, coef0=1, C=5)) # coef0 controls how much you model is influenced with high-degree polynomials\n",
    "]\n",
    ")\n",
    "\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel function projects the data into a greater space so that the data can be distinguished well. It is like mapping data into a function $\\phi$ and works as follows: $\\phi: x \\rightarrow \\phi(x)$ One kernel is called __Gaussian RBF (Radial Basis Function) Kernel__ which is $K(x, l) = e^{-\\frac{\\|x - l\\|^2}{2\\sigma^2}}$, where $\\|x - l\\|^2$ shows the distance of an instance $x$ from a landmark $l$. We need to find some landmarks and measure the similarity function Gaussian, and then create a feature for each landmark. Then, we will have a good chance to separate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm_clf', SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=5, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline(\n",
    "[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel='rbf', gamma=5, C=0.001)),\n",
    "]\n",
    ")\n",
    "\n",
    "rbf_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other kernels exist but used rarely. For example, __String Kernels__ can be used to classify text documents or DNA sequences. __LinearSVC__ is much faster than __SVC__ but it does not support kernels. It runs in $O(m \\times n)$ while __SVC__ runs in $O(m^2 \\times n) to O(m^3 \\times n)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM algorithm is quite versatile: not only does it support linear and nonlinear classification, but it also supports linear and nonlinear regression. The trick is to reverse the objective. Instead of trying to fit the largest possible street between two classes while limiting margin violations, SVM regression tries to fit as many instances as possible on the street while limiting margin violations. The width of the street is controlled by a hyperparameter $\\epsilon$. For this purpose, we can use Scikit-Learn's LinearSVR class to perform SVM Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=1.5, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle nonlinear regression tasks, we can use a kernalized SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:194: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=2, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='poly', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_poly_reg = SVR(kernel='poly', degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
